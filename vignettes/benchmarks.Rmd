---
title: "Benchmarks and other GO similarity methods"
author: "Casper Peters"
date: "`r Sys.Date()`"
output: 
  # rmarkdown::html_vignette:
  prettydoc::html_pretty:
    theme: cayman
    toc: true
    toc_depth: 4
    highlight: vignette
    copmressed_css: true
    code_folding: none
vignette: >
  %\VignetteIndexEntry{Benchmarks and other GO similarity methods}
  %\VignetteEngine{prettydoc::html_pretty}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Neccesary libraries:

```{r load_libs, warning = F, message = F, include = T}
## install ppipre seperately! (INtelliGO)
#install.packages("https://cran.r-project.org/src/contrib/Archive/ppiPre/ppiPre_1.9.tar.gz", repos=NULL)
## install csbl.go seperately (SimGIC)
#install.packages("http://csbi.ltdk.helsinki.fi/csbl.go/csbl.go_1.4.1.tar.gz", repos=NULL)

library(GAPGOM)
library(profvis)
library(GO.db)
library(graph)
library(ggplot2)
library(reshape2)
```

Benchmarks are an important part of getting to know how fast algorithms performs and what to expect. Thus, we will compare multiple example use cases to give an idea how fast the GAPGOM algorithms are compared to others. As well as try give an insight as to why certain algorithms have certain speeds. The profvis library will be used to determine the amount of time spent on each calculation as well as ram usage. 

Because this package is mainly made for human gene research, this is the model organism that will be used for all testing here. The Molecular Function or MF ontology will be used as the model ontology. Some internal function are used because they are needed for doing some of the operations required by base algorithsm/showing off the performance. Most of these results are based on random samples and shouldn't neccesarily be taken as-is/as a baseline. Instead, this benchmarking is more to give an idea about how well the processes scale.

Besides this, results have been pre-calculated and come with the package, as otherwise calculations times wouldn't be reasonable nor accurate. For some reasons running a vignette build takes longer than evaluating normal R code... All code blocks used to generate the results are included however.

The benchmarks have been run on two systems ; A laptop and a bigger server. Both with the following specs (obtained with `cat /proc/cpuinfo` & `cat /proc/meminfo`);

- Laptop;

CPU;
```
processor	: 3
vendor_id	: GenuineIntel
cpu family	: 6
model		: 78
model name	: Intel(R) Core(TM) i7-6500U CPU @ 2.50GHz
stepping	: 3
microcode	: 0xc6
cpu MHz		: 2800.039
cache size	: 4096 KB
physical id	: 0
siblings	: 4
core id		: 1
cpu cores	: 2
apicid		: 3
initial apicid	: 3
fpu		: yes
fpu_exception	: yes
cpuid level	: 22
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp flush_l1d
bugs		: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf
bogomips	: 5184.00
clflush size	: 64
cache_alignment	: 64
address sizes	: 39 bits physical, 48 bits virtual
power management:
```
Memory;
```
MemTotal:        8071404 kB
MemFree:          978056 kB
MemAvailable:    3087884 kB
Buffers:          367592 kB
Cached:          2616176 kB
SwapCached:            0 kB
Active:          4737256 kB
Inactive:        1944028 kB
Active(anon):    3699308 kB
Inactive(anon):   760208 kB
Active(file):    1037948 kB
Inactive(file):  1183820 kB
Unevictable:          48 kB
Mlocked:              48 kB
SwapTotal:       8000508 kB
SwapFree:        8000508 kB
Dirty:              5696 kB
Writeback:             0 kB
AnonPages:       3697580 kB
Mapped:           630132 kB
Shmem:            761956 kB
Slab:             279024 kB
SReclaimable:     198148 kB
SUnreclaim:        80876 kB
KernelStack:       11136 kB
PageTables:        47776 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    12036208 kB
Committed_AS:    9791644 kB
VmallocTotal:   34359738367 kB
VmallocUsed:           0 kB
VmallocChunk:          0 kB
HardwareCorrupted:     0 kB
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
CmaTotal:              0 kB
CmaFree:               0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
DirectMap4k:      166288 kB
DirectMap2M:     7077888 kB
DirectMap1G:     2097152 kB
```

- Server;

CPU;
```
processor	: 31
vendor_id	: GenuineIntel
cpu family	: 6
model		: 45
model name	: Intel(R) Xeon(R) CPU E5-2680 0 @ 2.70GHz
stepping	: 7
microcode	: 0x713
cpu MHz		: 2699.953
cache size	: 20480 KB
physical id	: 1
siblings	: 16
core id		: 7
cpu cores	: 8
apicid		: 47
initial apicid	: 47
fpu		: yes
fpu_exception	: yes
cpuid level	: 13
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx lahf_lm ida arat xsaveopt pln pts dtherm tpr_shadow vnmi flexpriority ept vpid
bogomips	: 5400.94
clflush size	: 64
cache_alignment	: 64
address sizes	: 46 bits physical, 48 bits virtual
power management:
```
Memory;
```
MemTotal:       264108916 kB
MemFree:        66614704 kB
Buffers:          262744 kB
Cached:         65338616 kB
SwapCached:        74732 kB
Active:         62788360 kB
Inactive:       44151044 kB
Active(anon):   56367000 kB
Inactive(anon): 23284424 kB
Active(file):    6421360 kB
Inactive(file): 20866620 kB
Unevictable:        7556 kB
Mlocked:            7556 kB
SwapTotal:      268387324 kB
SwapFree:       265225612 kB
Dirty:                88 kB
Writeback:             0 kB
AnonPages:      41301344 kB
Mapped:           212636 kB
Shmem:          38309896 kB
Slab:           21008548 kB
SReclaimable:     630584 kB
SUnreclaim:     20377964 kB
KernelStack:       12368 kB
PageTables:       125496 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    400441780 kB
Committed_AS:   89205012 kB
VmallocTotal:   34359738367 kB
VmallocUsed:    68290760 kB
VmallocChunk:   34093725116 kB
HardwareCorrupted:     0 kB
AnonHugePages:  11550720 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
DirectMap4k:      191424 kB
DirectMap2M:     5005312 kB
DirectMap1G:    265289728 kB
```

All processes are singlecore. (Some functions might be mutli-threadable however)

## lncRNApred (`expression_prediction_function`)

Since lncRNApred is based on expression values, we'll use the standard example that is included with the pacakge to make life easier. This algorithm should be linear depending on how many expression values you add. This will however not be shown because the actual calculations on the expression data are actually very fast. The main thing that slows down this algorithm is querying the GO terms and attaching them to the correct ID for the results.

```{r, eval=FALSE}
# Example with default dataset, take a look at the data documentation
# to fully grasp what's going on with making of the filter etc. (Biobase 
# ExpressionSet)

# make a filter of all the ids that contain a 0 in their expression row.
sort_list <- rownames(GAPGOM::ft5_example_data@assayData$exprs[
 apply(GAPGOM::ft5_example_data@assayData$exprs, 1, 
 function(row) {all(row==0)}),])
# set an artbitrary gene you want to find similarities for. (5th row in this
# case)
gid <- rownames(GAPGOM::ft5_example_data@assayData$exprs)[5]

p <- profvis::profvis({GAPGOM::expression_prediction_function(gid, 
                                     GAPGOM::ft5_example_data, 
                                     sort_list, 
                                     "mouse", 
                                     "BP"
                                     )
                     })
time <- max(p$x$message$prof$time)*10
mem <- max(p$x$message$prof$memalloc)
```
```{r}
# laptop
4710
# time
216.2178
# mem
# ---
# server
# time
8820
# mem
145.3423
```

The laptop took about ~5 seconds to complete the calculations, while the server took ~9 seconds. The most time is wasted in finding GO calculations.

## TopoICSim


There's three algorithms in the GAPGOM package in regards to TopoICSim; One on term level (`topo_ic_sim_term`), one on gene level (`topo_ic_sim_genes`) and one on geneset level (also `topo_ic_sim_genes`).
Because it is slightly difficult to determine which GOs are attributes of which genes, random genes will be sampled for testing some of the algorithms. The same goes for all GOs, as their path lookup might be different as well.

Prepare GO data for random data selection, topoICSim term calculation and some other neccesary variables.

```{r, eval=FALSE}
# prepare the godata for mouse and some other calculations later needed in benchmarking
organism <- "human"
ontology <- "BP"
go_data <- GAPGOM::set_go_data(organism, ontology)
```

Since go data does not neccesarily need to be prepared for functions, real use cases might be slower if it isn't prepared.

### TopoICSim - Term level

To get a good baseline of the underlying algorithm, multiple combinations of pairs will be tested against each other.

```{r topotitj, eval=FALSE}
# grab 15 random GOs (for term algorithm)
## sample(unique(go_data@geneAnno$GO), 15)
random_gos <- c("GO:0030177", "GO:0001771", "GO:0045715", "GO:0044330", "GO:0098780", 
"GO:1901006", "GO:0061143", "GO:0060025", "GO:0015695", "GO:0090074", 
"GO:0035445", "GO:0008595", "GO:1903634", "GO:1903826", "GO:0048389"
)
# print them for reproducability
## dput(random_gos)
# now compare all unique random GO pairs. (105 uniques).
unique_pairs <- GAPGOM:::.unique_combos(random_gos, random_gos)

times <- c()
mem_usages <- c()
for (i in seq_len(nrow(unique_pairs))) {
  prof_toptitj <- profvis({
    pair <- unique_pairs[i]
    go1 <- pair[[1]]
    go2 <- pair[[2]]
    GAPGOM::topo_ic_sim_term(ontology, organism, go1, go2, go_data = go_data)
  })
  time <- max(prof_toptitj$x$message$prof$time)*10
  mem <- max(prof_toptitj$x$message$prof$memalloc)
  mem_usages <- c(mem_usages, mem)
  times <- c(times, time)
  gc()
}
times_term <- times
mems_term <- mem_usages
```

```{r, fig.width=3, fig.height=3}
times_term_df <- data.frame(GAPGOM:::benchmarks$server_times_term, 
                          GAPGOM:::benchmarks$laptop_times_term, 
                          seq_len(105)
                          )
colnames(times_term_df) <- c("server", "laptop", "n")
times_term_df_melted <- melt(times_term_df, id="n")
colnames(times_term_df_melted) <- c("n", "machine", "milliseconds")
ggplot(times_term_df_melted, aes(x=machine, y=milliseconds, colour=machine)) + 
  geom_boxplot(notch=F) + 
  scale_y_continuous(breaks=pretty(times_term_df_melted$milliseconds, n = 5)) + 
  labs(title = paste(strwrap("Speed of term algorithm", width = 20), collapse = "\n")) + 
  theme(plot.title = element_text(hjust = 0.5))
```

The term algorithm seems to largely complete within 500ms, with ~1500ms being the max. The median is around ~100 ms, so most calculations last about that long, they also last at least 100ms it seems.

```{r, fig.width=3, fig.height=3}
mems_term_df <- data.frame(GAPGOM:::benchmarks$server_mems_term, 
                          GAPGOM:::benchmarks$laptop_mems_term, 
                          seq_len(105)
                          )
colnames(mems_term_df) <- c("server", "laptop", "n")
mems_term_df_melted <- melt(times_term_df, id="n")
colnames(mems_term_df_melted) <- c("n", "machine", "RAM")
ggplot(mems_term_df_melted, aes(x=machine, y=RAM, colour=machine)) + 
  geom_boxplot(notch=F) + 
  scale_y_continuous(breaks=pretty(mems_term_df_melted$RAM, n = 5)) + 
  labs(title = paste(strwrap("RAM usage for gene algorithm", width = 20), collapse = "\n")) + 
  theme(plot.title = element_text(hjust = 0.5))
```

The RAM usage is a bit more peculiar, there's more outliers for the server and the baseline is also higher. The reason why the baseline is higher is because the servers' R session apperantly had more in memory. The reason for the outliers could be that the server randomly had more heavy calculations, making the RAM increase. It makes sense, that where the GO's take longer, it would take up more memory too. The reason for the heavier load, is that all GO-pairs have a certain amount of common ancestors to loop through, depending on how far the GOs are removed from each other. This differs on a case-to-case basis and is hard to predict. Otherwise, it seems that there's a rough spread of ~100mb for both machines for this algorithm.

### TopoICSim - Gene level

To measure how the gene level algorithm performs with random genes, we will sample 10 random gene-pairs to test on it.

```{r, eval=FALSE, eval=FALSE}
## dput(sample(unique(go_data@geneAnno$ENTREZID), 5))
random_genes <- c("3848", "2824", "65108", "3988", "10800")

unique_pairs <- GAPGOM:::.unique_combos(random_genes, random_genes)

times <- c()
mem_usages <- c()
for (i in seq_len(nrow(unique_pairs))) {
  prof_topg1g2 <- profvis({
    pair <- unique_pairs[i]
    gene1 <- pair[[1]]
    gene2 <- pair[[2]]
    GAPGOM::topo_ic_sim_genes(ontology, organism, gene1, gene2, go_data=go_data)
  })
  time <- max(prof_topg1g2$x$message$prof$time)*10
  mem <- max(prof_topg1g2$x$message$prof$memalloc)
  mem_usages <- c(mem_usages, mem)
  times <- c(times, time)
  gc()
}
times
mem_usages
times_gen <- times
mems_gen <- mem_usages
```

```{r, fig.width=3, fig.height=3}
times_gene_df <- data.frame(GAPGOM:::benchmarks$server_times_gen, 
                          GAPGOM:::benchmarks$laptop_times_gen, 
                          seq_len(10)
                          )
colnames(times_gene_df) <- c("server", "laptop", "n")
times_gene_df_melted <- melt(times_gene_df, id="n")
times_gene_df_melted$value <- times_gene_df_melted$value/1000 
colnames(times_gene_df_melted) <- c("n", "machine", "seconds")
ggplot(times_gene_df_melted, aes(x=machine, y=seconds, colour=machine)) + 
  geom_boxplot(notch=F) + 
  scale_y_continuous(breaks=pretty(times_gene_df_melted$milliseconds, n = 5)) + 
  labs(title = paste(strwrap("Speed of gene algorithm", width = 20), collapse = "\n")) + 
  theme(plot.title = element_text(hjust = 0.5))
```

As you can see from the plots, the spread is pretty big. This is because every gene has different GOs, and each different GO-pair has a different relationship as well. All of this hugely affects calculation time, making it hard to predict how well an algorithm performs without knowing the specific implications of the selected underlying GOs. The spread seems pretty even between the two machines however, from ~25sec to ~30sec. This might indicate that there's groups of genes with certain n's of GOs.

```{r, fig.width=3, fig.height=3}
mems_gene_df <- data.frame(GAPGOM:::benchmarks$server_mems_gen, 
                          GAPGOM:::benchmarks$laptop_mems_gen, 
                          seq_len(10)
                          )
colnames(mems_gene_df) <- c("server", "laptop", "n")
mems_gene_df_melted <- melt(mems_gene_df, id="n")
colnames(mems_gene_df_melted) <- c("n", "machine", "RAM")
ggplot(mems_gene_df_melted, aes(x=machine, y=RAM, colour=machine)) + 
  geom_boxplot(notch=F) + 
  scale_y_continuous(breaks=pretty(mems_gene_df_melted$RAM, n = 5)) + 
  labs(title = paste(strwrap("RAM usage for gene algorithm", width = 20), collapse = "\n")) + 
  theme(plot.title = element_text(hjust = 0.5))
```

Funnily enough, the spread the gene algorithm takes up is less, and also very consistent. For the server most RAM usages are around ~230Mb, and for the laptop it's even more consistent; All 4 quartiles are on ~215Mb! With a few outliers specifically on 180Mb.

### TopoICSim - Geneset level (and scalability)

To measure scalability on geneset-level, [the pfam clan gene set is used](https://pfam.xfam.org/family/PF00171). The reason we're not choosing random genes, is because this is not something representative in a practical use case scenario. Most of the time, you want to compare genes that belong within a certain pathway. Rather than looking at completely random genes that don't have a relationship.

```{r, eval=FALSE}
list1=c("126133","221","218","216","8854","220","219","160428","224","222","8659","501","64577","223","217","4329","10840","7915", "5832")
times <- c()
mem_usages <- c()
for (i in seq(length(list1)-1)) {
  sampled_list <- list1[1:(i+1)]
  print(sampled_list)
  p <- profvis({
     GAPGOM::topo_ic_sim_genes(ontology, organism, sampled_list, sampled_list, drop=NULL, go_data=go_data)
   })
  time <- max(p$x$message$prof$time)*10
  mem <- max(p$x$message$prof$memalloc)
  mem_usages <- c(mem_usages, mem)
  times <- c(times, time)
  gc()
}
times
mem_usages
times_genset <- times
mems_genset <- mem_usages
```

```{r, fig.width=6, fig.height=3}
final_times <- data.frame(GAPGOM:::benchmarks$server_times_genset, 
                          GAPGOM:::benchmarks$laptop_times_genset, 
                          seq_along(GAPGOM:::benchmarks$laptop_times_genset)
                          )
colnames(final_times) <- c("server", "laptop", "n")
final_times_melted <- melt(final_times, id="n")
final_times_melted$value <- final_times_melted$value/1000/60
colnames(final_times_melted) <- c("Genes in geneset", "Machine", "Minutes")
p <- ggplot(data=final_times_melted, aes(x=`Genes in geneset`, y=Minutes, colour=Machine)) + 
  geom_point() + 
  labs(title = paste(strwrap("Speed of TopoICSim geneset algorithm", width = 20), collapse = "\n")) + 
  theme(plot.title = element_text(hjust = 0.5))
p
p + stat_smooth(method = "lm", formula = y ~ x + I(x^2), size = 1)
```

As you can see, TopoICSim does not scale well and fits an exponential curve. It is however also visible that there's a certain "stepping" occuring. This is probably because genes share similar GO terms, which are stored temporarily as to prevent unnecesary calculations. However this prevention method loses it's grip the more genes you keep adding, especially unrelated/less related genes. This shows that the underlying curve is exponential. This is logical because the amount of calculations done is completely dependent on the list-lengths. The confidence interval between the two machines are shared in the beginning of the curve mostly, the curve is a bit more steep on the server because of lower single-core performance.

```{r, fig.width=3, fig.height=3}
mems_geneset_df <- data.frame(GAPGOM:::benchmarks$server_mems_genset, 
                          GAPGOM:::benchmarks$laptop_mems_genset, 
                          seq_len(18)
                          )
colnames(mems_geneset_df) <- c("server", "laptop", "n")
mems_geneset_df_melted <- melt(mems_geneset_df, id="n")
colnames(mems_geneset_df_melted) <- c("n", "machine", "RAM")
ggplot(mems_geneset_df_melted, aes(x=machine, y=RAM, colour=machine)) + 
  geom_boxplot(notch=F) + 
  scale_y_continuous(breaks=pretty(mems_geneset_df_melted$RAM, n = 5)) + 
  labs(title = paste(strwrap("RAM usage for geneset algorithm", width = 20), collapse = "\n")) + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r, fig.width=6, fig.height=3}
ggplot(mems_geneset_df_melted, aes(x=n, y=RAM, colour=machine)) + 
  geom_point()  + 
  scale_y_continuous(breaks=pretty(mems_geneset_df_melted$RAM, n = 5)) + 
  labs(title = paste(strwrap("RAM usage for geneset algorithm", width = 20), collapse = "\n")) + 
  theme(plot.title = element_text(hjust = 0.5))

```

The RAM is quite similar to the calculation times, but has however, got one flaw; The last memory-point of the laptop was calculated in a seperate R version, where thus the memory was reset. This shouldn't matter if we think of the algorithm in term of the iterations performed, but it does. The laptop's memory usage is way less than the ones before it, meaning there is a lot of RAM leaks left in memory after the algorithm is done. This is also why it is advised to restart your R session every now and then. The RAM leaks seem to be attributed to used of `apply` and are hard to prevent.

### Overall thoughts

Although the speed can be reasonably determined for the algorithms, RAM is a bit more tricky because of a lot of variables. This can be caused by differences in R session, memory leaks and other semi-random events/structuring of the code. Thus the only real thing that we can conclude is that there is quite a lot of RAM leaks, especially in the case of the geneset algorithm because of its iterative nature.

## Comparisons between algorithms

For comparisons between other algorithms, `expression_prediction_function` will be left out as it is the only algorithm based on expression values. 

## For code reviewers;

Finally, for code reviewers, you can just call the result of each `profvis` to get a flame graph and other details of code speed.